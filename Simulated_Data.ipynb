{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear time-series generator (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_medium_difficulty_dataset(\n",
    "    n_samples=5000,\n",
    "    n_cont_features=10,\n",
    "    n_cat_features=5,\n",
    "    n_classes=3,\n",
    "    lstm_sequence_length=None,  # optional\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Medium-difficulty synthetic dataset created by:\n",
    "    - Random nonlinear MLP (hidden truth function)\n",
    "    - Numeric interactions\n",
    "    - Useful + useless noise\n",
    "    - Balanced classes\n",
    "    - Suitable reshaping for MLP, CNN, LSTM\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # ============================================================\n",
    "    # 1. Generate base features\n",
    "    # ============================================================\n",
    "\n",
    "    # Continuous base features\n",
    "    X_cont = np.random.randn(n_samples, n_cont_features)\n",
    "\n",
    "    # Add nonlinear transforms ‚Üí adds medium complexity\n",
    "    X_nonlin = np.column_stack([\n",
    "        np.sin(X_cont[:, 0]),\n",
    "        X_cont[:, 1] * X_cont[:, 2],\n",
    "        np.tanh(X_cont[:, 3]),\n",
    "        np.exp(-X_cont[:, 4]**2),\n",
    "        (X_cont[:, 5] > 0).astype(float)\n",
    "    ])\n",
    "\n",
    "    # Noise features (useless)\n",
    "    X_noise = np.random.randn(n_samples, 10)\n",
    "\n",
    "    # Categorical\n",
    "    # Slightly imbalanced, but not extreme\n",
    "    X_cat = np.column_stack([\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples, p=[0.4,0.2,0.2,0.1,0.1]),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples, p=[0.5,0.1,0.1,0.1,0.2]),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Combine everything\n",
    "    X = np.hstack([X_cont, X_nonlin, X_noise, X_cat])\n",
    "    total_features = X.shape[1]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 2. Hidden Random Neural Network to Generate Class Probabilities\n",
    "    # ============================================================\n",
    "\n",
    "    hidden_model = nn.Sequential(\n",
    "        nn.Linear(total_features, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, n_classes)\n",
    "    )\n",
    "\n",
    "    for p in hidden_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = hidden_model(torch.tensor(X, dtype=torch.float32))\n",
    "        probs = torch.softmax(logits, dim=1).numpy()\n",
    "\n",
    "    y = np.argmax(probs, axis=1)\n",
    "\n",
    "    # Balance classes (important)\n",
    "    # Re-sample to balance the dataset moderately\n",
    "    final_idx = []\n",
    "    for c in range(n_classes):\n",
    "        cls_idx = np.where(y == c)[0]\n",
    "        n_target = n_samples // n_classes\n",
    "        if len(cls_idx) > n_target:\n",
    "            cls_idx = np.random.choice(cls_idx, size=n_target, replace=False)\n",
    "        else:\n",
    "            cls_idx = np.random.choice(cls_idx, size=n_target, replace=True)\n",
    "        final_idx.append(cls_idx)\n",
    "\n",
    "    final_idx = np.concatenate(final_idx)\n",
    "    np.random.shuffle(final_idx)\n",
    "\n",
    "    X = X[final_idx]\n",
    "    y = y[final_idx]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 3. Prepare MLP + CNN versions\n",
    "    # ============================================================\n",
    "\n",
    "    X_mlp = X.copy()\n",
    "    X_cnn = X.reshape(X.shape[0], 1, -1)   # (batch, channel=1, features)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 4. Prepare LSTM Version\n",
    "    # ============================================================\n",
    "\n",
    "    if lstm_sequence_length is None:\n",
    "        # choose a divisor of total_features that gives medium sequence length (not too small)\n",
    "        divisors = [d for d in range(5, total_features+1) if total_features % d == 0]\n",
    "        divisors.sort()\n",
    "        lstm_sequence_length = divisors[len(divisors)//2]  # pick mid-level divisor\n",
    "\n",
    "    if total_features % lstm_sequence_length != 0:\n",
    "        raise ValueError(\"Chosen sequence length doesn't divide features\")\n",
    "\n",
    "    features_per_step = total_features // lstm_sequence_length\n",
    "    X_lstm = X.reshape(X.shape[0], lstm_sequence_length, features_per_step)\n",
    "\n",
    "    return X_mlp, X_cnn, X_lstm, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP --> receives the raw feature matrix X\n",
    "* CNN --> Receives the same 15 features, but arranged as a single channel: This is just a reshape, no new data is created.\n",
    "* LSTM --> Receives the same 15 features, but split into time steps: This also contains the same numbers, merely reorganized so the LSTM can process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mlp, X_cnn, X_lstm, y = generate_medium_difficulty_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_mlp, columns=[f\"f{i}\" for i in range(X_mlp.shape[1])])\n",
    "\n",
    "# Convert categorical columns back to int\n",
    "for c in [f\"f{i}\" for i in range(25, 30)]:\n",
    "    df[c] = df[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24']\n",
      "Categorical cols: ['f25', 'f26', 'f27', 'f28', 'f29']\n",
      "df columns: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29']\n"
     ]
    }
   ],
   "source": [
    "num_cols = [f\"f{i}\" for i in range(25)]\n",
    "cat_cols = [f\"f{i}\" for i in range(25, 30)]\n",
    "\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"df columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols] = df[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0      float64\n",
      "f1      float64\n",
      "f2      float64\n",
      "f3      float64\n",
      "f4      float64\n",
      "f5      float64\n",
      "f6      float64\n",
      "f7      float64\n",
      "f8      float64\n",
      "f9      float64\n",
      "f10     float64\n",
      "f11     float64\n",
      "f12     float64\n",
      "f13     float64\n",
      "f14     float64\n",
      "f15     float64\n",
      "f16     float64\n",
      "f17     float64\n",
      "f18     float64\n",
      "f19     float64\n",
      "f20     float64\n",
      "f21     float64\n",
      "f22     float64\n",
      "f23     float64\n",
      "f24     float64\n",
      "f25    category\n",
      "f26    category\n",
      "f27    category\n",
      "f28    category\n",
      "f29    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_S1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocess_S2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
    "            (\"scaler\", MinMaxScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"target\", TargetEncoder())\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "identity = FunctionTransformer(lambda x: x)\n",
    "\n",
    "preprocess_S3 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", IterativeImputer(max_iter=3)),\n",
    "            (\"scaler\", RobustScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"identity\", identity)\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 (4998, 50)\n",
      "S2 (4998, 30)\n",
      "S3 (4998, 30)\n"
     ]
    }
   ],
   "source": [
    "for name, preproc in [(\"S1\", preprocess_S1), (\"S2\", preprocess_S2), (\"S3\", preprocess_S3)]:\n",
    "    Xp = preproc.fit_transform(df, y)\n",
    "    print(name, Xp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4998, 30)\n",
      "(4998, 1, 30)\n",
      "(4998, 10, 3)\n",
      "(4998,)\n"
     ]
    }
   ],
   "source": [
    "print(X_mlp.shape)\n",
    "print(X_cnn.shape)\n",
    "print(X_lstm.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.710808</td>\n",
       "      <td>0.308763</td>\n",
       "      <td>2.355629</td>\n",
       "      <td>-0.042540</td>\n",
       "      <td>0.180019</td>\n",
       "      <td>-0.310260</td>\n",
       "      <td>0.667262</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>-0.676047</td>\n",
       "      <td>-0.114353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959218</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>-0.357152</td>\n",
       "      <td>1.688971</td>\n",
       "      <td>0.092737</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287306</td>\n",
       "      <td>-0.189568</td>\n",
       "      <td>-0.060016</td>\n",
       "      <td>0.385205</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.133395</td>\n",
       "      <td>1.308918</td>\n",
       "      <td>0.565596</td>\n",
       "      <td>-0.958804</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557216</td>\n",
       "      <td>1.644009</td>\n",
       "      <td>1.646138</td>\n",
       "      <td>0.225626</td>\n",
       "      <td>-0.827511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -1.710808  0.308763  2.355629 -0.042540  0.180019 -0.310260  0.667262   \n",
       "1 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "2 -0.287306 -0.189568 -0.060016  0.385205 -0.000263 -0.133395  1.308918   \n",
       "3 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "4 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "\n",
       "         f7        f8        f9  ...       f20       f21       f22       f23  \\\n",
       "0  0.362209 -0.676047 -0.114353  ...  0.959218 -0.110982 -0.357152  1.688971   \n",
       "1  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "2  0.565596 -0.958804  0.740674  ... -0.557216  1.644009  1.646138  0.225626   \n",
       "3  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "4  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "\n",
       "        f24  f25  f26  f27  f28  f29  \n",
       "0  0.092737  3.0  4.0  1.0  3.0  0.0  \n",
       "1 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "2 -0.827511  1.0  3.0  0.0  1.0  4.0  \n",
       "3 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "4 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_mlp, columns=[f\"f{i}\" for i in range(X_mlp.shape[1])])\n",
    "\n",
    "num_cols = [f\"f{i}\" for i in range(25)]\n",
    "cat_cols = [f\"f{i}\" for i in range(25, 30)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_S1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_S2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
    "            (\"scaler\", MinMaxScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"target\", TargetEncoder())\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "identity = FunctionTransformer(lambda x: x)\n",
    "\n",
    "preprocess_S3 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", IterativeImputer(max_iter=3)),\n",
    "            (\"scaler\", RobustScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"identity\", identity)\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 (4998, 50)\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "S2 (4998, 30)\n",
      "S3 (4998, 30)\n"
     ]
    }
   ],
   "source": [
    "for name, preproc in [(\"S1\", preprocess_S1), (\"S2\", preprocess_S2), (\"S3\", preprocess_S3)]:\n",
    "    Xp = preproc.fit_transform(df, y)\n",
    "    print(name, Xp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24']\n",
      "Categorical cols: ['f25', 'f26', 'f27', 'f28', 'f29']\n",
      "df columns: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"df columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S1 = MedianImpute ‚Üí StandardScaler ‚Üí OneHotEncoder\n",
    "* S2 = KNNImputer(k=5) ‚Üí MinMaxScaler ‚Üí TargetEncode\n",
    "* S3 = MICE(3 iters) ‚Üí RobustScaler ‚Üí Embedding Layer (this will be ignored for MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def split_for_strategy(X, strategy, num_numeric=25):\n",
    "    \"\"\"\n",
    "    S1 & S2 ‚Üí fully numeric (no categorical input)\n",
    "    S3 ‚Üí numeric + raw categorical integer IDs\n",
    "    \"\"\"\n",
    "    if strategy in [\"S1\", \"S2\"]:\n",
    "        return torch.tensor(X, dtype=torch.float32), None\n",
    "    \n",
    "    # S3 ‚Üí must split numeric vs categorical\n",
    "    X_num = torch.tensor(X[:, :num_numeric], dtype=torch.float32)\n",
    "    X_cat = torch.tensor(X[:, num_numeric:].astype(int), dtype=torch.long)\n",
    "    return X_num, X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_with_Embeddings(nn.Module):\n",
    "    def __init__(self, num_numeric=25, cat_cardinalities=[5]*5, embed_dim=8, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layers (only used in S3)\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(card, embed_dim) for card in cat_cardinalities\n",
    "        ])\n",
    "\n",
    "        # Will determine input dim dynamically\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def initialize_first_layer(self, input_dim):\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(input_dim, 64)\n",
    "\n",
    "    def forward(self, x_num, x_cat=None):\n",
    "\n",
    "        if x_cat is None:\n",
    "            # S1 / S2\n",
    "            mlp_input = x_num\n",
    "        else:\n",
    "            # S3 ‚Äî embed categorical\n",
    "            embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            embedded = torch.cat(embedded, dim=1)\n",
    "            mlp_input = torch.cat([x_num, embedded], dim=1)\n",
    "\n",
    "        # Lazy initialization once we know input size\n",
    "        if self.fc1 is None:\n",
    "            self.initialize_first_layer(mlp_input.shape[1])\n",
    "\n",
    "        x = torch.relu(self.fc1(mlp_input))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, X_num, X_cat, y, epochs=20):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_num, X_cat)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, X_num, X_cat, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_num, X_cat)\n",
    "        preds = preds.argmax(dim=1)\n",
    "\n",
    "    acc = accuracy_score(y, preds)\n",
    "    f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running MLP with S1\n",
      "\n",
      "üöÄ Running MLP with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running MLP with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.633953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.494439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.546340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0   MLP            S1    0.6896  0.633953\n",
       "1   MLP            S2    0.5056  0.494439\n",
       "2   MLP            S3    0.6024  0.546340"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "preprocessors = {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}\n",
    "\n",
    "# Use MLP dataset\n",
    "X_mlp, _, _, y = generate_medium_difficulty_dataset()\n",
    "\n",
    "# Split\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "for strategy, preproc in preprocessors.items():\n",
    "    print(f\"\\nüöÄ Running MLP with {strategy}\")\n",
    "\n",
    "    # 1. Preprocess\n",
    "    X_train_prep = preproc.fit_transform(X_train_raw, y_train)\n",
    "    X_test_prep = preproc.transform(X_test_raw)\n",
    "\n",
    "    # 2. Split numeric vs cats for S3\n",
    "    X_train_num, X_train_cat = split_for_strategy(X_train_prep, strategy)\n",
    "    X_test_num, X_test_cat = split_for_strategy(X_test_prep, strategy)\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # 3. Build model\n",
    "    model = MLP_with_Embeddings(\n",
    "        num_numeric=25,\n",
    "        cat_cardinalities=[5]*5,\n",
    "        embed_dim=8,\n",
    "        num_classes=3\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 4. Train\n",
    "    train(model, optimizer, criterion, X_train_num, X_train_cat, y_train_tensor)\n",
    "\n",
    "    # 5. Eval\n",
    "    acc, f1 = evaluate(model, X_test_num, X_test_cat, y_test_tensor)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"MLP\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularCNN(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=16,\n",
    "            out_channels=32,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  # (batch, 16, L)\n",
    "        x = self.relu(self.conv2(x))  # (batch, 32, L)\n",
    "        x = self.pool(x).squeeze(-1)  # (batch, 32)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, optimizer, criterion, X, y, epochs=20):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_cnn(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        preds = preds.argmax(dim=1)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running CNN with S1\n",
      "\n",
      "üöÄ Running CNN with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running CNN with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.183844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.222277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>0.304918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0   CNN            S1    0.3352  0.183844\n",
       "1   CNN            S2    0.3448  0.222277\n",
       "2   CNN            S3    0.3912  0.304918"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# TRAIN/TEST SPLIT FOR CNN EXPERIMENT\n",
    "# ----------------------------------------\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "results_cnn = []\n",
    "\n",
    "for strategy, preproc in {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Running CNN with {strategy}\")\n",
    "\n",
    "    # 1. Fit preprocessing on TRAIN only\n",
    "    X_train_prep = preproc.fit_transform(df_train, y_train)\n",
    "    X_test_prep  = preproc.transform(df_test)\n",
    "\n",
    "    # 2. Convert to tensors & reshape for CNN: (batch, channels=1, features)\n",
    "    X_train_tensor = torch.tensor(X_train_prep, dtype=torch.float32).reshape(\n",
    "        -1, 1, X_train_prep.shape[1]\n",
    "    )\n",
    "    X_test_tensor = torch.tensor(X_test_prep, dtype=torch.float32).reshape(\n",
    "        -1, 1, X_test_prep.shape[1]\n",
    "    )\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_tensor  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # 3. Build model\n",
    "    model = TabularCNN(num_features=X_train_prep.shape[1], num_classes=3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 4. Train CNN\n",
    "    train_cnn(model, optimizer, criterion, X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    acc, f1 = eval_cnn(model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # 6. Store results\n",
    "    results_cnn.append({\n",
    "        \"Model\": \"CNN\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes,\n",
    "                 cat_cardinalities=None, embed_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.has_cat = cat_cardinalities is not None\n",
    "\n",
    "        if self.has_cat:\n",
    "            # One embedding per categorical feature\n",
    "            self.embeddings = nn.ModuleList([\n",
    "                nn.Embedding(card, embed_dim)\n",
    "                for card in cat_cardinalities\n",
    "            ])\n",
    "            lstm_input_dim = input_dim + len(cat_cardinalities)*embed_dim\n",
    "        else:\n",
    "            lstm_input_dim = input_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_seq, x_cat=None):\n",
    "\n",
    "        if self.has_cat:\n",
    "            # Embed all categorical columns\n",
    "            embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            embedded = torch.cat(embedded, dim=1)\n",
    "            # Expand over time dimension\n",
    "            embedded = embedded.unsqueeze(1).repeat(1, x_seq.shape[1], 1)\n",
    "            x = torch.cat([x_seq, embedded], dim=2)\n",
    "        else:\n",
    "            x = x_seq\n",
    "\n",
    "        _, (h_last, _) = self.lstm(x)\n",
    "        out = self.fc(h_last[-1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(model, optimizer, criterion, X_num, X_cat, y, epochs=15):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_num, X_cat)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_lstm(model, X_num, X_cat, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_num, X_cat)\n",
    "        preds = preds.argmax(1)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running LSTM with S1\n",
      "\n",
      "üöÄ Running LSTM with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running LSTM with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.227162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>0.204548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>0.534728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0  LSTM            S1    0.3392  0.227162\n",
       "1  LSTM            S2    0.3584  0.204548\n",
       "2  LSTM            S3    0.5760  0.534728"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 5       # ‚≠ê FIXED: must divide NUM_COLS\n",
    "NUM_COLS = 25     # 25 numeric features\n",
    "\n",
    "results_lstm = []\n",
    "\n",
    "preprocessors = {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}\n",
    "\n",
    "# Splits made earlier (same as for MLP + CNN)\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=42)\n",
    "\n",
    "for strategy, preproc in preprocessors.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Running LSTM with {strategy}\")\n",
    "\n",
    "    # 1. Preprocess\n",
    "    X_train_prep = preproc.fit_transform(df_train, y_train)\n",
    "    X_test_prep = preproc.transform(df_test)\n",
    "\n",
    "    # ---- NUMERIC BLOCK ----\n",
    "    X_train_num = X_train_prep[:, :NUM_COLS]\n",
    "    X_test_num  = X_test_prep[:, :NUM_COLS]\n",
    "\n",
    "    # reshape into sequences\n",
    "    features_per_step = NUM_COLS // SEQ_LEN\n",
    "\n",
    "    X_train_num = torch.tensor(\n",
    "        X_train_num.reshape(-1, SEQ_LEN, features_per_step),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    X_test_num = torch.tensor(\n",
    "        X_test_num.reshape(-1, SEQ_LEN, features_per_step),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # ---- CATEGORICAL BLOCK (only for S3) ----\n",
    "    if strategy == \"S3\":\n",
    "        X_train_cat_raw = X_train_prep[:, NUM_COLS:].astype(int)\n",
    "        X_test_cat_raw  = X_test_prep[:, NUM_COLS:].astype(int)\n",
    "\n",
    "        X_train_cat = torch.tensor(X_train_cat_raw, dtype=torch.long)\n",
    "        X_test_cat  = torch.tensor(X_test_cat_raw, dtype=torch.long)\n",
    "\n",
    "        cat_cardinalities = [5,5,5,5,5]\n",
    "    else:\n",
    "        X_train_cat = None\n",
    "        X_test_cat = None\n",
    "        cat_cardinalities = None\n",
    "\n",
    "    # ---- Labels ----\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_t  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=features_per_step,\n",
    "        hidden_dim=32,\n",
    "        num_layers=1,\n",
    "        num_classes=3,\n",
    "        cat_cardinalities=cat_cardinalities\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- Train ----\n",
    "    train_lstm(model, optimizer, criterion, X_train_num, X_train_cat, y_train_t)\n",
    "\n",
    "    # ---- Evaluate ----\n",
    "    acc, f1 = eval_lstm(model, X_test_num, X_test_cat, y_test_t)\n",
    "\n",
    "    results_lstm.append({\n",
    "        \"Model\": \"LSTM\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_lstm = pd.DataFrame(results_lstm)\n",
    "results_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
