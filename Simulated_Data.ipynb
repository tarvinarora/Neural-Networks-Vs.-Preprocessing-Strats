{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear time-series generator (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_medium_difficulty_dataset(\n",
    "    n_samples=5000,\n",
    "    n_cont_features=10,\n",
    "    n_cat_features=5,\n",
    "    n_classes=3,\n",
    "    lstm_sequence_length=None,  # optional\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Medium-difficulty synthetic dataset created by:\n",
    "    - Random nonlinear MLP (hidden truth function)\n",
    "    - Numeric interactions\n",
    "    - Useful + useless noise\n",
    "    - Balanced classes\n",
    "    - Suitable reshaping for MLP, CNN, LSTM\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # ============================================================\n",
    "    # 1. Generate base features\n",
    "    # ============================================================\n",
    "\n",
    "    # Continuous base features\n",
    "    X_cont = np.random.randn(n_samples, n_cont_features)\n",
    "\n",
    "    # Add nonlinear transforms ‚Üí adds medium complexity\n",
    "    X_nonlin = np.column_stack([\n",
    "        np.sin(X_cont[:, 0]),\n",
    "        X_cont[:, 1] * X_cont[:, 2],\n",
    "        np.tanh(X_cont[:, 3]),\n",
    "        np.exp(-X_cont[:, 4]**2),\n",
    "        (X_cont[:, 5] > 0).astype(float)\n",
    "    ])\n",
    "\n",
    "    # Noise features (useless)\n",
    "    X_noise = np.random.randn(n_samples, 10)\n",
    "\n",
    "    # Categorical\n",
    "    # Slightly imbalanced, but not extreme\n",
    "    X_cat = np.column_stack([\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples, p=[0.4,0.2,0.2,0.1,0.1]),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples, p=[0.5,0.1,0.1,0.1,0.2]),\n",
    "        np.random.choice([0,1,2,3,4], size=n_samples)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Combine everything\n",
    "    X = np.hstack([X_cont, X_nonlin, X_noise, X_cat])\n",
    "    total_features = X.shape[1]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 2. Hidden Random Neural Network to Generate Class Probabilities\n",
    "    # ============================================================\n",
    "\n",
    "    hidden_model = nn.Sequential(\n",
    "        nn.Linear(total_features, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, n_classes)\n",
    "    )\n",
    "\n",
    "    for p in hidden_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = hidden_model(torch.tensor(X, dtype=torch.float32))\n",
    "        probs = torch.softmax(logits, dim=1).numpy()\n",
    "\n",
    "    y = np.argmax(probs, axis=1)\n",
    "\n",
    "    # Balance classes (important)\n",
    "    # Re-sample to balance the dataset moderately\n",
    "    final_idx = []\n",
    "    for c in range(n_classes):\n",
    "        cls_idx = np.where(y == c)[0]\n",
    "        n_target = n_samples // n_classes\n",
    "        if len(cls_idx) > n_target:\n",
    "            cls_idx = np.random.choice(cls_idx, size=n_target, replace=False)\n",
    "        else:\n",
    "            cls_idx = np.random.choice(cls_idx, size=n_target, replace=True)\n",
    "        final_idx.append(cls_idx)\n",
    "\n",
    "    final_idx = np.concatenate(final_idx)\n",
    "    np.random.shuffle(final_idx)\n",
    "\n",
    "    X = X[final_idx]\n",
    "    y = y[final_idx]\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 3. Prepare MLP + CNN versions\n",
    "    # ============================================================\n",
    "\n",
    "    X_mlp = X.copy()\n",
    "    X_cnn = X.reshape(X.shape[0], 1, -1)   # (batch, channel=1, features)\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # 4. Prepare LSTM Version\n",
    "    # ============================================================\n",
    "\n",
    "    if lstm_sequence_length is None:\n",
    "        # choose a divisor of total_features that gives medium sequence length (not too small)\n",
    "        divisors = [d for d in range(5, total_features+1) if total_features % d == 0]\n",
    "        divisors.sort()\n",
    "        lstm_sequence_length = divisors[len(divisors)//2]  # pick mid-level divisor\n",
    "\n",
    "    if total_features % lstm_sequence_length != 0:\n",
    "        raise ValueError(\"Chosen sequence length doesn't divide features\")\n",
    "\n",
    "    features_per_step = total_features // lstm_sequence_length\n",
    "    X_lstm = X.reshape(X.shape[0], lstm_sequence_length, features_per_step)\n",
    "\n",
    "    return X_mlp, X_cnn, X_lstm, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP --> receives the raw feature matrix X\n",
    "* CNN --> Receives the same 15 features, but arranged as a single channel: This is just a reshape, no new data is created.\n",
    "* LSTM --> Receives the same 15 features, but split into time steps: This also contains the same numbers, merely reorganized so the LSTM can process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mlp, X_cnn, X_lstm, y = generate_medium_difficulty_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_mlp, columns=[f\"f{i}\" for i in range(X_mlp.shape[1])])\n",
    "\n",
    "# Convert categorical columns back to int\n",
    "for c in [f\"f{i}\" for i in range(25, 30)]:\n",
    "    df[c] = df[c].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24']\n",
      "Categorical cols: ['f25', 'f26', 'f27', 'f28', 'f29']\n",
      "df columns: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29']\n"
     ]
    }
   ],
   "source": [
    "num_cols = [f\"f{i}\" for i in range(25)]\n",
    "cat_cols = [f\"f{i}\" for i in range(25, 30)]\n",
    "\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"df columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols] = df[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0      float64\n",
      "f1      float64\n",
      "f2      float64\n",
      "f3      float64\n",
      "f4      float64\n",
      "f5      float64\n",
      "f6      float64\n",
      "f7      float64\n",
      "f8      float64\n",
      "f9      float64\n",
      "f10     float64\n",
      "f11     float64\n",
      "f12     float64\n",
      "f13     float64\n",
      "f14     float64\n",
      "f15     float64\n",
      "f16     float64\n",
      "f17     float64\n",
      "f18     float64\n",
      "f19     float64\n",
      "f20     float64\n",
      "f21     float64\n",
      "f22     float64\n",
      "f23     float64\n",
      "f24     float64\n",
      "f25    category\n",
      "f26    category\n",
      "f27    category\n",
      "f28    category\n",
      "f29    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_S1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocess_S2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", KNNImputer(n_neighbors=5)),\n",
    "            (\"scaler\", MinMaxScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"target\", TargetEncoder())\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "identity = FunctionTransformer(lambda x: x)\n",
    "\n",
    "preprocess_S3 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", IterativeImputer(max_iter=3)),\n",
    "            (\"scaler\", RobustScaler())\n",
    "        ]), num_cols),\n",
    "\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"identity\", identity)\n",
    "        ]), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1 (4998, 50)\n",
      "S2 (4998, 30)\n",
      "S3 (4998, 30)\n"
     ]
    }
   ],
   "source": [
    "for name, preproc in [(\"S1\", preprocess_S1), (\"S2\", preprocess_S2), (\"S3\", preprocess_S3)]:\n",
    "    Xp = preproc.fit_transform(df, y)\n",
    "    print(name, Xp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4998, 30)\n",
      "(4998, 1, 30)\n",
      "(4998, 10, 3)\n",
      "(4998,)\n"
     ]
    }
   ],
   "source": [
    "print(X_mlp.shape)\n",
    "print(X_cnn.shape)\n",
    "print(X_lstm.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.710808</td>\n",
       "      <td>0.308763</td>\n",
       "      <td>2.355629</td>\n",
       "      <td>-0.042540</td>\n",
       "      <td>0.180019</td>\n",
       "      <td>-0.310260</td>\n",
       "      <td>0.667262</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>-0.676047</td>\n",
       "      <td>-0.114353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959218</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>-0.357152</td>\n",
       "      <td>1.688971</td>\n",
       "      <td>0.092737</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287306</td>\n",
       "      <td>-0.189568</td>\n",
       "      <td>-0.060016</td>\n",
       "      <td>0.385205</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.133395</td>\n",
       "      <td>1.308918</td>\n",
       "      <td>0.565596</td>\n",
       "      <td>-0.958804</td>\n",
       "      <td>0.740674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557216</td>\n",
       "      <td>1.644009</td>\n",
       "      <td>1.646138</td>\n",
       "      <td>0.225626</td>\n",
       "      <td>-0.827511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.290487</td>\n",
       "      <td>1.542297</td>\n",
       "      <td>1.159330</td>\n",
       "      <td>-0.103989</td>\n",
       "      <td>-0.488313</td>\n",
       "      <td>-0.609441</td>\n",
       "      <td>-2.585653</td>\n",
       "      <td>0.353820</td>\n",
       "      <td>0.780324</td>\n",
       "      <td>0.137902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059107</td>\n",
       "      <td>-2.016945</td>\n",
       "      <td>0.774187</td>\n",
       "      <td>0.088960</td>\n",
       "      <td>-1.605960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0 -1.710808  0.308763  2.355629 -0.042540  0.180019 -0.310260  0.667262   \n",
       "1 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "2 -0.287306 -0.189568 -0.060016  0.385205 -0.000263 -0.133395  1.308918   \n",
       "3 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "4 -1.290487  1.542297  1.159330 -0.103989 -0.488313 -0.609441 -2.585653   \n",
       "\n",
       "         f7        f8        f9  ...       f20       f21       f22       f23  \\\n",
       "0  0.362209 -0.676047 -0.114353  ...  0.959218 -0.110982 -0.357152  1.688971   \n",
       "1  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "2  0.565596 -0.958804  0.740674  ... -0.557216  1.644009  1.646138  0.225626   \n",
       "3  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "4  0.353820  0.780324  0.137902  ... -0.059107 -2.016945  0.774187  0.088960   \n",
       "\n",
       "        f24  f25  f26  f27  f28  f29  \n",
       "0  0.092737  3.0  4.0  1.0  3.0  0.0  \n",
       "1 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "2 -0.827511  1.0  3.0  0.0  1.0  4.0  \n",
       "3 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "4 -1.605960  0.0  0.0  4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_mlp, columns=[f\"f{i}\" for i in range(X_mlp.shape[1])])\n",
    "\n",
    "num_cols = [f\"f{i}\" for i in range(25)]\n",
    "cat_cols = [f\"f{i}\" for i in range(25, 30)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24']\n",
      "Categorical cols: ['f25', 'f26', 'f27', 'f28', 'f29']\n",
      "df columns: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29']\n"
     ]
    }
   ],
   "source": [
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"df columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = {\n",
    "    \"Low\":    {\"hidden\": 32,  \"dropout\": 0.2, \"lr\": 1e-3},\n",
    "    \"Medium\": {\"hidden\": 64,  \"dropout\": 0.2, \"lr\": 1e-3},\n",
    "    \"High\":   {\"hidden\": 128, \"dropout\": 0.1, \"lr\": 5e-4}\n",
    "}\n",
    "\n",
    "LATIN_SQUARE = {\n",
    "    \"MLP\":  {\"Low\": \"S1\", \"Medium\": \"S2\", \"High\": \"S3\"},\n",
    "    \"CNN\":  {\"Low\": \"S2\", \"Medium\": \"S3\", \"High\": \"S1\"},\n",
    "    \"LSTM\": {\"Low\": \"S3\", \"Medium\": \"S1\", \"High\": \"S2\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* S1 = MedianImpute ‚Üí StandardScaler ‚Üí OneHotEncoder\n",
    "* S2 = KNNImputer(k=5) ‚Üí MinMaxScaler ‚Üí TargetEncode\n",
    "* S3 = MICE(3 iters) ‚Üí RobustScaler ‚Üí Embedding Layer (this will be ignored for MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def split_for_strategy(X, strategy, num_numeric=25):\n",
    "    \"\"\"\n",
    "    S1 & S2 ‚Üí fully numeric (no categorical input)\n",
    "    S3 ‚Üí numeric + raw categorical integer IDs\n",
    "    \"\"\"\n",
    "    if strategy in [\"S1\", \"S2\"]:\n",
    "        return torch.tensor(X, dtype=torch.float32), None\n",
    "    \n",
    "    # S3 ‚Üí must split numeric vs categorical\n",
    "    X_num = torch.tensor(X[:, :num_numeric], dtype=torch.float32)\n",
    "    X_cat = torch.tensor(X[:, num_numeric:].astype(int), dtype=torch.long)\n",
    "    return X_num, X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_with_Embeddings(nn.Module):\n",
    "    def __init__(self, hidden_dim=64, dropout=0.2, \n",
    "                 num_numeric=25, cat_cardinalities=[5]*5, \n",
    "                 embed_dim=8, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_p = dropout\n",
    "\n",
    "        # Embeddings (S3 only)\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(card, embed_dim)\n",
    "        for card in cat_cardinalities])\n",
    "\n",
    "        # lazy init\n",
    "        self.fc1 = None\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def initialize_first_layer(self, input_dim):\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(input_dim, self.hidden_dim)\n",
    "\n",
    "    def forward(self, x_num, x_cat=None):\n",
    "\n",
    "        if x_cat is None:\n",
    "            mlp_input = x_num\n",
    "        else:\n",
    "            embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            embedded = torch.cat(embedded, dim=1)\n",
    "            mlp_input = torch.cat([x_num, embedded], dim=1)\n",
    "\n",
    "        if self.fc1 is None:\n",
    "            self.initialize_first_layer(mlp_input.shape[1])\n",
    "\n",
    "        x = torch.relu(self.fc1(mlp_input))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, X_num, X_cat, y, epochs=20):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_num, X_cat)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate(model, X_num, X_cat, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_num, X_cat)\n",
    "        preds = preds.argmax(dim=1)\n",
    "\n",
    "    acc = accuracy_score(y, preds)\n",
    "    f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running MLP with S1\n",
      "\n",
      "üöÄ Running MLP with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running MLP with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>0.705511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.573197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.730453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0   MLP            S1    0.7272  0.705511\n",
       "1   MLP            S2    0.6088  0.573197\n",
       "2   MLP            S3    0.7320  0.730453"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "preprocessors = {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}\n",
    "\n",
    "# Use MLP dataset\n",
    "X_mlp, _, _, y = generate_medium_difficulty_dataset()\n",
    "\n",
    "# Split\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "for strategy, preproc in preprocessors.items():\n",
    "    print(f\"\\nüöÄ Running MLP with {strategy}\")\n",
    "\n",
    "    # 1. Preprocess\n",
    "    X_train_prep = preproc.fit_transform(X_train_raw, y_train)\n",
    "    X_test_prep = preproc.transform(X_test_raw)\n",
    "\n",
    "    # 2. Split numeric vs cats for S3\n",
    "    X_train_num, X_train_cat = split_for_strategy(X_train_prep, strategy)\n",
    "    X_test_num, X_test_cat = split_for_strategy(X_test_prep, strategy)\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # 3. Build model\n",
    "    model = MLP_with_Embeddings(\n",
    "        num_numeric=25,\n",
    "        cat_cardinalities=[5]*5,\n",
    "        embed_dim=8,\n",
    "        num_classes=3\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 4. Train\n",
    "    train(model, optimizer, criterion, X_train_num, X_train_cat, y_train_tensor)\n",
    "\n",
    "    # 5. Eval\n",
    "    acc, f1 = evaluate(model, X_test_num, X_test_cat, y_test_tensor)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"MLP\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularCNN(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=3, hidden_dim=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim*2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, optimizer, criterion, X, y, epochs=20):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_cnn(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        preds = preds.argmax(dim=1)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running CNN with S1\n",
      "\n",
      "üöÄ Running CNN with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running CNN with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.314655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.557091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.311492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0   CNN            S1    0.3952  0.314655\n",
       "1   CNN            S2    0.5408  0.557091\n",
       "2   CNN            S3    0.3928  0.311492"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# TRAIN/TEST SPLIT FOR CNN EXPERIMENT\n",
    "# ----------------------------------------\n",
    "df_train, df_test, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "results_cnn = []\n",
    "\n",
    "for strategy, preproc in {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Running CNN with {strategy}\")\n",
    "\n",
    "    # 1. Fit preprocessing on TRAIN only\n",
    "    X_train_prep = preproc.fit_transform(df_train, y_train)\n",
    "    X_test_prep  = preproc.transform(df_test)\n",
    "\n",
    "    # 2. Convert to tensors & reshape for CNN: (batch, channels=1, features)\n",
    "    X_train_tensor = torch.tensor(X_train_prep, dtype=torch.float32).reshape(\n",
    "        -1, 1, X_train_prep.shape[1]\n",
    "    )\n",
    "    X_test_tensor = torch.tensor(X_test_prep, dtype=torch.float32).reshape(\n",
    "        -1, 1, X_test_prep.shape[1]\n",
    "    )\n",
    "\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_tensor  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # 3. Build model\n",
    "    model = TabularCNN(num_features=X_train_prep.shape[1], num_classes=3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 4. Train CNN\n",
    "    train_cnn(model, optimizer, criterion, X_train_tensor, y_train_tensor)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    acc, f1 = eval_cnn(model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # 6. Store results\n",
    "    results_cnn.append({\n",
    "        \"Model\": \"CNN\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Experiment (S1, S2 and S3 comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_layers=1, dropout=0.2,\n",
    "                 num_classes=3, cat_cardinalities=None, embed_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.has_cat = cat_cardinalities is not None\n",
    "\n",
    "        if self.has_cat:\n",
    "            self.embeddings = nn.ModuleList(\n",
    "                [nn.Embedding(card, embed_dim) for card in cat_cardinalities]\n",
    "            )\n",
    "            lstm_input_dim = input_dim + len(cat_cardinalities)*embed_dim\n",
    "        else:\n",
    "            lstm_input_dim = input_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            lstm_input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x_seq, x_cat=None):\n",
    "\n",
    "        if self.has_cat:\n",
    "            embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "            embedded = torch.cat(embedded, dim=1)\n",
    "            embedded = embedded.unsqueeze(1).repeat(1, x_seq.shape[1], 1)\n",
    "            x_seq = torch.cat([x_seq, embedded], dim=2)\n",
    "\n",
    "        _, (h_last, _) = self.lstm(x_seq)\n",
    "        h_last = self.dropout(h_last[-1])\n",
    "        return self.fc(h_last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(model, optimizer, criterion, X_num, X_cat, y, epochs=15):\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X_num, X_cat)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_lstm(model, X_num, X_cat, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_num, X_cat)\n",
    "        preds = preds.argmax(1)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        f1 = f1_score(y, preds, average=\"weighted\")\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running LSTM with S1\n",
      "\n",
      "üöÄ Running LSTM with S2\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üöÄ Running LSTM with S3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.4344</td>\n",
       "      <td>0.346086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>0.306571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.533032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Preprocessing  Accuracy  F1 Score\n",
       "0  LSTM            S1    0.4344  0.346086\n",
       "1  LSTM            S2    0.4024  0.306571\n",
       "2  LSTM            S3    0.5952  0.533032"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "SEQ_LEN = 5       # ‚≠ê FIXED: must divide NUM_COLS\n",
    "NUM_COLS = 25     # 25 numeric features\n",
    "\n",
    "results_lstm = []\n",
    "\n",
    "preprocessors = {\n",
    "    \"S1\": preprocess_S1,\n",
    "    \"S2\": preprocess_S2,\n",
    "    \"S3\": preprocess_S3\n",
    "}\n",
    "\n",
    "# Splits made earlier (same as for MLP + CNN)\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=0.25, random_state=42)\n",
    "\n",
    "for strategy, preproc in preprocessors.items():\n",
    "\n",
    "    print(f\"\\nüöÄ Running LSTM with {strategy}\")\n",
    "\n",
    "    # 1. Preprocess\n",
    "    X_train_prep = preproc.fit_transform(df_train, y_train)\n",
    "    X_test_prep = preproc.transform(df_test)\n",
    "\n",
    "    # ---- NUMERIC BLOCK ----\n",
    "    X_train_num = X_train_prep[:, :NUM_COLS]\n",
    "    X_test_num  = X_test_prep[:, :NUM_COLS]\n",
    "\n",
    "    # reshape into sequences\n",
    "    features_per_step = NUM_COLS // SEQ_LEN\n",
    "\n",
    "    X_train_num = torch.tensor(\n",
    "        X_train_num.reshape(-1, SEQ_LEN, features_per_step),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    X_test_num = torch.tensor(\n",
    "        X_test_num.reshape(-1, SEQ_LEN, features_per_step),\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # ---- CATEGORICAL BLOCK (only for S3) ----\n",
    "    if strategy == \"S3\":\n",
    "        X_train_cat_raw = X_train_prep[:, NUM_COLS:].astype(int)\n",
    "        X_test_cat_raw  = X_test_prep[:, NUM_COLS:].astype(int)\n",
    "\n",
    "        X_train_cat = torch.tensor(X_train_cat_raw, dtype=torch.long)\n",
    "        X_test_cat  = torch.tensor(X_test_cat_raw, dtype=torch.long)\n",
    "\n",
    "        cat_cardinalities = [5,5,5,5,5]\n",
    "    else:\n",
    "        X_train_cat = None\n",
    "        X_test_cat = None\n",
    "        cat_cardinalities = None\n",
    "\n",
    "    # ---- Labels ----\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_t  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=features_per_step,\n",
    "        hidden_dim=32,\n",
    "        num_layers=1,\n",
    "        num_classes=3,\n",
    "        cat_cardinalities=cat_cardinalities\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- Train ----\n",
    "    train_lstm(model, optimizer, criterion, X_train_num, X_train_cat, y_train_t)\n",
    "\n",
    "    # ---- Evaluate ----\n",
    "    acc, f1 = eval_lstm(model, X_test_num, X_test_cat, y_test_t)\n",
    "\n",
    "    results_lstm.append({\n",
    "        \"Model\": \"LSTM\",\n",
    "        \"Preprocessing\": strategy,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_lstm = pd.DataFrame(results_lstm)\n",
    "results_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• MODEL=MLP | CAPACITY=Low\n",
      "\n",
      "üî• MODEL=MLP | CAPACITY=Medium\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üî• MODEL=MLP | CAPACITY=High\n",
      "\n",
      "üî• MODEL=CNN | CAPACITY=Low\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "\n",
      "üî• MODEL=CNN | CAPACITY=Medium\n",
      "\n",
      "üî• MODEL=CNN | CAPACITY=High\n",
      "\n",
      "üî• MODEL=LSTM | CAPACITY=Low\n",
      "\n",
      "üî• MODEL=LSTM | CAPACITY=Medium\n",
      "\n",
      "üî• MODEL=LSTM | CAPACITY=High\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Preprocessing</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Low</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>0.393535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>Medium</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>0.571585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>High</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.723899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Low</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.272417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.7016</td>\n",
       "      <td>0.690031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>High</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>0.558531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Low</td>\n",
       "      <td>S3</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.530564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>S1</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>0.649705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>High</td>\n",
       "      <td>S2</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>0.160641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Capacity Preprocessing  Accuracy  F1 Score\n",
       "0   MLP      Low            S1    0.4176  0.393535\n",
       "1   MLP   Medium            S2    0.6032  0.571585\n",
       "2   MLP     High            S3    0.7368  0.723899\n",
       "3   CNN      Low            S2    0.3456  0.272417\n",
       "4   CNN   Medium            S3    0.7016  0.690031\n",
       "5   CNN     High            S1    0.5512  0.558531\n",
       "6  LSTM      Low            S3    0.5704  0.530564\n",
       "7  LSTM   Medium            S1    0.6480  0.649705\n",
       "8  LSTM     High            S2    0.3264  0.160641"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_RESULTS = []\n",
    "\n",
    "models = [\"MLP\", \"CNN\", \"LSTM\"]\n",
    "capacities = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "for model_name in models:\n",
    "    for cap in capacities:\n",
    "\n",
    "        print(f\"\\nüî• MODEL={model_name} | CAPACITY={cap}\")\n",
    "\n",
    "        # Determine which preprocessing strategy using Latin Square\n",
    "        strategy = LATIN_SQUARE[model_name][cap]\n",
    "        preproc = preprocessors[strategy]\n",
    "\n",
    "        cfg = CAPACITY[cap]   # hidden_dim, dropout, lr\n",
    "\n",
    "        # === Preprocess ===\n",
    "        X_train_prep = preproc.fit_transform(df_train, y_train)\n",
    "        X_test_prep = preproc.transform(df_test)\n",
    "\n",
    "        # ---- MLP ----\n",
    "        if model_name == \"MLP\":\n",
    "            X_train_num, X_train_cat = split_for_strategy(X_train_prep, strategy)\n",
    "            X_test_num, X_test_cat   = split_for_strategy(X_test_prep, strategy)\n",
    "\n",
    "            model = MLP_with_Embeddings(\n",
    "                hidden_dim=cfg[\"hidden\"],\n",
    "                dropout=cfg[\"dropout\"]\n",
    "            )\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            train(model, optimizer, criterion, X_train_num, X_train_cat, torch.tensor(y_train))\n",
    "            acc, f1 = evaluate(model, X_test_num, X_test_cat, torch.tensor(y_test))\n",
    "\n",
    "        # ---- CNN ----\n",
    "        elif model_name == \"CNN\":\n",
    "            X_train_tensor = torch.tensor(X_train_prep, dtype=torch.float32).reshape(-1, 1, X_train_prep.shape[1])\n",
    "            X_test_tensor  = torch.tensor(X_test_prep,  dtype=torch.float32).reshape(-1, 1, X_test_prep.shape[1])\n",
    "\n",
    "            model = TabularCNN(\n",
    "                num_features=X_train_prep.shape[1],\n",
    "                hidden_dim=cfg[\"hidden\"],\n",
    "                dropout=cfg[\"dropout\"]\n",
    "            )\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            train_cnn(model, optimizer, criterion, X_train_tensor, torch.tensor(y_train))\n",
    "            acc, f1 = eval_cnn(model, X_test_tensor, torch.tensor(y_test))\n",
    "\n",
    "        # ---- LSTM ----\n",
    "        else:\n",
    "            NUM_COLS = 25\n",
    "            SEQ_LEN = 5\n",
    "            features_per_step = NUM_COLS // SEQ_LEN\n",
    "\n",
    "            X_train_num = torch.tensor(X_train_prep[:, :NUM_COLS].reshape(-1, SEQ_LEN, features_per_step), dtype=torch.float32)\n",
    "            X_test_num  = torch.tensor(X_test_prep[:, :NUM_COLS].reshape(-1, SEQ_LEN, features_per_step), dtype=torch.float32)\n",
    "\n",
    "            if strategy == \"S3\":\n",
    "                X_train_cat = torch.tensor(X_train_prep[:, NUM_COLS:].astype(int))\n",
    "                X_test_cat  = torch.tensor(X_test_prep[:, NUM_COLS:].astype(int))\n",
    "                cats = [5]*5\n",
    "            else:\n",
    "                X_train_cat = None\n",
    "                X_test_cat = None\n",
    "                cats = None\n",
    "\n",
    "            model = LSTMClassifier(\n",
    "                input_dim=features_per_step,\n",
    "                hidden_dim=cfg[\"hidden\"],\n",
    "                dropout=cfg[\"dropout\"],\n",
    "                num_classes=3,\n",
    "                cat_cardinalities=cats\n",
    "            )\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            train_lstm(model, optimizer, criterion, X_train_num, X_train_cat, torch.tensor(y_train))\n",
    "            acc, f1 = eval_lstm(model, X_test_num, X_test_cat, torch.tensor(y_test))\n",
    "\n",
    "        FINAL_RESULTS.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Capacity\": cap,\n",
    "            \"Preprocessing\": strategy,\n",
    "            \"Accuracy\": acc,\n",
    "            \"F1 Score\": f1\n",
    "        })\n",
    "\n",
    "pd.DataFrame(FINAL_RESULTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
